{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6977fb",
   "metadata": {
    "id": "fb6977fb"
   },
   "source": [
    "## 1.1 Cài đặt thư viện\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31349cf",
   "metadata": {
    "id": "c31349cf"
   },
   "source": [
    "## 1.2 Thêm các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde3c40b",
   "metadata": {
    "id": "cde3c40b"
   },
   "outputs": [],
   "source": [
    "#import standar dependentcies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260d5d9e",
   "metadata": {
    "id": "260d5d9e"
   },
   "outputs": [],
   "source": [
    "#import tansorflow dependentcies\n",
    "# Import tensorflow dependencies - Functional API\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import random\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BGJGrRQoRY5P",
   "metadata": {
    "id": "BGJGrRQoRY5P"
   },
   "source": [
    "## 1.3 Set GPU Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "PEyyYI7DRU6S",
   "metadata": {
    "id": "PEyyYI7DRU6S"
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1b905b",
   "metadata": {
    "id": "7a1b905b"
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "\n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "\n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    # Scale image to be between 0 and 1\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a23a2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74619ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(data_dir):\n",
    "    # Load the LFW dataset from the specified directory\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for person_dir in os.listdir(data_dir):\n",
    "        person_path = os.path.join(data_dir, person_dir)\n",
    "        \n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "        \n",
    "        for image_name in os.listdir(person_path):\n",
    "            image_path = os.path.join(person_path, image_name)\n",
    "            \n",
    "            # Read in image from file path\n",
    "            byte_img = tf.io.read_file(image_path)\n",
    "            # Load in the image \n",
    "            img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "            # Preprocessing steps - resizing the image to be 100x100x3\n",
    "            img = tf.image.resize(img, (100,100))\n",
    "            # Scale image to be between 0 and 1 \n",
    "            img = img / 255.0\n",
    "            \n",
    "            images.append(img)\n",
    "            # Assign a unique label to each person\n",
    "            person_label = person_dir\n",
    "            labels.append(person_label)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d179fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_siamese_pairs(images, labels, target_size):\n",
    "    pairs_anchor = []\n",
    "    pairs_val = []\n",
    "    target = []\n",
    "    \n",
    "    # Create positive pairs (same person)\n",
    "    for i in range(len(images)-(target_size + 1)):\n",
    "        for j in range(i+1, i + (target_size + 1)):\n",
    "            if labels[i] == labels[j]:\n",
    "                pairs_anchor.append((images[i]))\n",
    "                pairs_val.append((images[j]))\n",
    "                target.append(1)\n",
    "#         print('lable =  1')\n",
    "    # Create negative pairs (different persons)\n",
    "    for i in range(len(images)-(target_size + 1)):\n",
    "        for j in range(i+1, i + (target_size + 1)):\n",
    "            if labels[i] != labels[j]:\n",
    "                pairs_anchor.append((images[i]))\n",
    "                pairs_val.append((images[j]))\n",
    "                target.append(0)\n",
    "#         print('lable =  0')\n",
    "    \n",
    "    return pairs_anchor, pairs_val, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lPZ314lzhOZN",
   "metadata": {
    "id": "lPZ314lzhOZN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs_anchor = np.load('siamese_dataset_pairs_anchor.npy')\n",
    "pairs_val = np.load('siamese_dataset_pairs_val.npy')\n",
    "labels_dataset = np.load('siamese_dataset_target.npy')\n",
    "\n",
    "pairs_anchor = np.array(pairs_anchor[:600])\n",
    "pairs_val = np.array(pairs_val[:600])\n",
    "labels_dataset = np.array(labels_dataset[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a34a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_dataset = tf.convert_to_tensor(pairs_anchor)\n",
    "pairs_dataset = tf.convert_to_tensor(pairs_val)\n",
    "labels_dataset = tf.convert_to_tensor(labels_dataset)\n",
    "\n",
    "# Giải phóng biến sau khi sử dụng\n",
    "del pairs_anchor, pairs_val\n",
    "\n",
    "# Tạo tập dữ liệu 2 lớp được gán nhãn\n",
    "data = tf.data.Dataset.zip((\n",
    "    tf.data.Dataset.from_tensor_slices(anchor_dataset),\n",
    "    tf.data.Dataset.from_tensor_slices(pairs_dataset),\n",
    "    tf.data.Dataset.from_tensor_slices(labels_dataset)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c750151",
   "metadata": {},
   "outputs": [],
   "source": [
    "del anchor_dataset, pairs_dataset,labels_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2859e9",
   "metadata": {
    "id": "7b2859e9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca61235",
   "metadata": {
    "id": "bca61235"
   },
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.cache()\n",
    "# trộn dữ liệu, chỉ định bộ đệm 1024\n",
    "data = data.shuffle(buffer_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020cf390",
   "metadata": {
    "id": "020cf390"
   },
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b00a898c",
   "metadata": {
    "id": "b00a898c"
   },
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))  # Bỏ qua data train\n",
    "test_data = test_data.take(round(len(data)*.3))  # Lấy 30% cuối cùng\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n",
    "\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefb46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ad167",
   "metadata": {
    "id": "053ad167"
   },
   "source": [
    "# Build embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8b1f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac510f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9012ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9daacb1",
   "metadata": {},
   "source": [
    "## 4.2 Build Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41258a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Euclidean distance calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b1f5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340b32c",
   "metadata": {},
   "source": [
    "## 4.3 Make Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc16df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6aad834",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46ee04ef",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d46e8",
   "metadata": {
    "id": "866d46e8"
   },
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416e9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(a,b,c):\n",
    "    for idx, batch in enumerate(test_data):\n",
    "        y_hat = siamese_model.predict([batch[0], batch[1]])\n",
    "        y_true = batch[2]\n",
    "        y_hat_round = []\n",
    "        for prediction in y_hat:\n",
    "            if prediction > 0.9:\n",
    "                y_hat_round.append(1)\n",
    "            else:\n",
    "                y_hat_round.append(0)\n",
    "        true = 0\n",
    "\n",
    "        for idx in range(0, len(y_hat_round)-1):\n",
    "            if y_hat_round[idx] == y_true[idx]:\n",
    "                true = true + 1\n",
    "            # print(true)\n",
    "        correct_ratio = true/len(y_hat)\n",
    "    print('val_accuracy',correct_ratio)\n",
    "    \n",
    "    return correct_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be5cb4",
   "metadata": {
    "id": "d6be5cb4"
   },
   "source": [
    "## 5.1 Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c80f50f8",
   "metadata": {
    "id": "c80f50f8"
   },
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88c1ff",
   "metadata": {
    "id": "0e88c1ff"
   },
   "source": [
    "## 5.2 Establish Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3354ca",
   "metadata": {
    "id": "3f3354ca"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2be3e",
   "metadata": {
    "id": "2ca2be3e"
   },
   "source": [
    "## 5.3 Build Train Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe94f62",
   "metadata": {
    "id": "ffe94f62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "        \n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c0513",
   "metadata": {
    "id": "d08c0513"
   },
   "source": [
    "## 5.4 Build Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "749c5c8c",
   "metadata": {
    "id": "749c5c8c"
   },
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8004aa",
   "metadata": {
    "id": "5f8004aa"
   },
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "\n",
    "    loss_numpys = []\n",
    "    r_results = []\n",
    "    p_results = []\n",
    "    val_accuracy = []\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        \n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        loss_numpys.append(loss.numpy())\n",
    "        r_results.append(r.result().numpy())\n",
    "        p_results.append(p.result().numpy())\n",
    "        \n",
    "        accuracy_calculation = calculate_accuracy(test_input, test_val, y_true)\n",
    "        val_accuracy.append(accuracy_calculation)\n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    # return val_accuracy\n",
    "    return (loss_numpys, r_results, p_results, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb16d4",
   "metadata": {
    "id": "96fb16d4"
   },
   "source": [
    "## 5.5 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "676bb2a1",
   "metadata": {
    "id": "676bb2a1"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "TTSwRRbgVWB6",
   "metadata": {
    "id": "TTSwRRbgVWB6"
   },
   "outputs": [],
   "source": [
    "siamese_model.compile(loss='BinaryCrossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46008259",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "46008259",
    "outputId": "8bf7cd19-b0f5-4416-942e-f45348cfe43f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "27/27 [==============================] - 18s 515ms/step\n",
      "0.6735531 0.35748792 0.556391\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_accuracy 0.5\n",
      "\n",
      " Epoch 2/50\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "27/27 [==============================] - 13s 476ms/step\n",
      "0.6665629 0.13942307 0.58\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_accuracy 0.0\n",
      "\n",
      " Epoch 3/50\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "27/27 [==============================] - 13s 475ms/step\n",
      "0.6908799 0.17258883 0.68\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "val_accuracy 0.5\n",
      "\n",
      " Epoch 4/50\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "27/27 [==============================] - 13s 469ms/step\n",
      "0.50328946 0.42380953 0.649635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "val_accuracy 0.75\n",
      "\n",
      " Epoch 5/50\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "27/27 [==============================] - 13s 472ms/step\n",
      "0.7668184 0.407767 0.67741936\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "val_accuracy 0.0\n",
      "\n",
      " Epoch 6/50\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "12/27 [============>.................] - ETA: 7s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_numpy, r_result, p_result, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [32], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data, EPOCHS)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Run train step here\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_step(batch)\n\u001b[1;32m---> 20\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     r\u001b[38;5;241m.\u001b[39mupdate_state(batch[\u001b[38;5;241m2\u001b[39m], yhat)\n\u001b[0;32m     22\u001b[0m     p\u001b[38;5;241m.\u001b[39mupdate_state(batch[\u001b[38;5;241m2\u001b[39m], yhat) \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2249\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2247\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2248\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1307\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1307\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3409\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_numpy, r_result, p_result, val_accuracy = train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hYh0987YzcCo",
   "metadata": {
    "id": "hYh0987YzcCo"
   },
   "outputs": [],
   "source": [
    "# create x-axis values\n",
    "x = range(len(val_accuracy))\n",
    "# loss.numpy(), r.result().numpy(), p.result().numpy(), val_accuracy\n",
    "# plot the data\n",
    "plt.plot(x, loss_numpy, label='loss')\n",
    "plt.plot(x, r_result, label='r.result')\n",
    "plt.plot(x, p_result, label='p.result')\n",
    "plt.plot(x, val_accuracy, label='val_accuracy')\n",
    "\n",
    "# Đánh dấu điểm có giá trị lớn nhất\n",
    "max_index = val_accuracy.index(max(val_accuracy))\n",
    "plt.scatter(x[max_index], val_accuracy[max_index], color='red', label='Max Value')\n",
    "\n",
    "plt.annotate(f'({x[max_index]}, {val_accuracy[max_index]})',\n",
    "             xy=(x[max_index], val_accuracy[max_index]), xytext=(x[max_index]+0.3, val_accuracy[max_index]-0.2),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "# Đánh dấu điểm có giá trị nhỏ nhất\n",
    "min_index = loss_numpy.index(min(loss_numpy))\n",
    "plt.scatter(x[min_index], loss_numpy[min_index], color='red', label='Min Value')\n",
    "\n",
    "plt.annotate(f'({x[min_index]}, {loss_numpy[min_index]})',\n",
    "             xy=(x[min_index], loss_numpy[min_index]), xytext=(x[min_index]+0.3, loss_numpy[min_index]+0.2),\n",
    "             arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "\n",
    "\n",
    "\n",
    "# add labels\n",
    "plt.title('Facial Verification using LFW')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Hiển thị bảng chú thích\n",
    "legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), bbox_transform=plt.gcf().transFigure)\n",
    "\n",
    "\n",
    "# plt.grid(True)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, color='gray')\n",
    "\n",
    "# save image\n",
    "plt.savefig('Facial Verification using LFW(kha_quan)(600)(50).png', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800465ab",
   "metadata": {
    "id": "800465ab",
    "tags": []
   },
   "source": [
    "# 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3cea47",
   "metadata": {
    "id": "9d3cea47"
   },
   "source": [
    "## 6.1 Import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edb15c",
   "metadata": {
    "id": "d9edb15c"
   },
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763768b7",
   "metadata": {
    "id": "763768b7"
   },
   "source": [
    "## 6.2 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92de35b",
   "metadata": {
    "id": "a92de35b"
   },
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368b83f",
   "metadata": {
    "id": "e368b83f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_hat = siamese_model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f8c67",
   "metadata": {
    "id": "0c8f8c67",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Post processing the results\n",
    "[1 if prediction > 0.8 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65eb91",
   "metadata": {
    "id": "db65eb91",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b520a",
   "metadata": {
    "id": "ca5b520a"
   },
   "source": [
    "## 6.3 Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bceacf2",
   "metadata": {
    "id": "6bceacf2"
   },
   "outputs": [],
   "source": [
    "# Creating a metric object\n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value\n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2beb8f",
   "metadata": {
    "id": "1e2beb8f"
   },
   "outputs": [],
   "source": [
    "# Creating a metric object\n",
    "m = Precision()\n",
    "\n",
    "# Calculating the recall value\n",
    "m.update_state(y_true, y_hat)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb9f74",
   "metadata": {
    "id": "d0bb9f74"
   },
   "outputs": [],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat)\n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iFGyyBZV1rS5",
   "metadata": {
    "id": "iFGyyBZV1rS5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_resul = 0\n",
    "for idx in range(0,100):\n",
    "\n",
    "    test_input, test_val, y_true = test_data.as_numpy_iterator().next()\n",
    "\n",
    "    y_hat = siamese_model.predict([test_input, test_val])\n",
    "    y_hat_round = []\n",
    "    for prediction in y_hat:\n",
    "        if prediction > 0.9:\n",
    "            y_hat_round.append(1)\n",
    "        else:\n",
    "            y_hat_round.append(0)\n",
    "    true = 0\n",
    "    for idx in range(len(y_true)):\n",
    "        if y_hat_round[idx] == y_true[idx]:\n",
    "            true = true + 1\n",
    "    print(true)\n",
    "    test_resul = test_resul + true\n",
    "\n",
    "correct_ratio = test_resul/len(y_hat)\n",
    "print(correct_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5uJLIL-sA0Ym",
   "metadata": {
    "id": "5uJLIL-sA0Ym"
   },
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "THvupu7fA3Pq",
   "metadata": {
    "id": "THvupu7fA3Pq"
   },
   "outputs": [],
   "source": [
    "test_input = np.load('test_siamese_dataset_pairs_anchor.npy')\n",
    "test_val = np.load('test_siamese_dataset_pairs_val.npy')\n",
    "y_true = np.load('test_siamese_dataset_target.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCtjQx0fO4G1",
   "metadata": {
    "id": "cCtjQx0fO4G1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat_round = []\n",
    "for prediction in y_hat:\n",
    "    if prediction > 0.9:\n",
    "        y_hat_round.append(1)\n",
    "    else:\n",
    "        y_hat_round.append(0)\n",
    "true = 0\n",
    "\n",
    "for idx in range(0, len(y_hat_round)-1):\n",
    "    if y_hat_round[idx] == y_true[idx]:\n",
    "        true = true + 1\n",
    "#     print(true)\n",
    "\n",
    "correct_ratio = true/len(y_hat)\n",
    "print(correct_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce525bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.load('LFW_pairs_anchor.npy')\n",
    "test_val = np.load('LFW_pairs_val.npy')\n",
    "y_true = np.load('LFW_target.npy')\n",
    "\n",
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat_round = []\n",
    "for prediction in y_hat:\n",
    "    if prediction > 0.95:\n",
    "        y_hat_round.append(1)\n",
    "    else:\n",
    "        y_hat_round.append(0)\n",
    "true = 0\n",
    "\n",
    "for idx in range(0, len(y_hat_round)-1):\n",
    "    if y_hat_round[idx] == y_true[idx]:\n",
    "        true = true + 1\n",
    "  # print(true)\n",
    "correct_ratio = true/len(y_hat)\n",
    "print(correct_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1c8eb",
   "metadata": {
    "id": "d5e1c8eb"
   },
   "source": [
    "## 6.4 Viz Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb0f45",
   "metadata": {
    "id": "11fb0f45",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set plot size\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Set first subplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[0])\n",
    "\n",
    "# Set second subplot\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[0])\n",
    "\n",
    "# Renders cleanly\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be203a57",
   "metadata": {
    "id": "be203a57"
   },
   "source": [
    "# 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8cedc",
   "metadata": {
    "id": "f6a8cedc"
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodel_LFW(600)(50).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7926e12",
   "metadata": {
    "id": "a7926e12"
   },
   "outputs": [],
   "source": [
    "# # Reload model\n",
    "# model = tf.keras.models.load_model('siamesemodel_LFW_v1_0.h5',\n",
    "#                                    custom_objects={'L1Dist':L1Dist, 'contrastive_loss':contrastive_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df332b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model \n",
    "model = tf.keras.models.load_model('siamesemodel_LFW(600)(50).h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
